{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video properties:\n",
      "FPS: 29.7\n",
      "Frame count: 744\n",
      "Width: 106\n",
      "Height: 190\n",
      "1007\n",
      "Reconstructing frame: 0\n",
      "20   1007\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Complex data not supported\n[  7726.46607809-535.89642716j -36617.37582047+921.91373074j\n -52517.65484624-214.17991472j ... -11618.70913071-851.8317396j\n  45980.76264328+179.14825763j  56188.83518192+963.35016074j]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 121\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;66;03m# Reconstruct the frame using L1 minimization (Lasso)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m         lasso \u001b[38;5;241m=\u001b[39m Lasso(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)  \u001b[38;5;66;03m# Adjust alpha and max_iter\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m         \u001b[43mlasso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m         vector_of_frame[i] \u001b[38;5;241m=\u001b[39m lasso\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Reshape the reconstructed frame vector into the downsampled shape\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Initialize reconstructed_frame_vector as an empty list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:905\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[0;32m    904\u001b[0m     X_copied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept\n\u001b[1;32m--> 905\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_copied\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    915\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    916\u001b[0m         y, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    917\u001b[0m     )\n\u001b[0;32m    919\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1162\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1146\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1172\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[1;32m-> 1172\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1182\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:925\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    917\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;66;03m# It is possible that the np.array(..) gave no warning. This happens\u001b[39;00m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# when no dtype conversion happened, for example dtype = None. The\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# result is that np.array(..) produces an array of complex dtype\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# and we need to catch and raise exception for such cases.\u001b[39;00m\n\u001b[1;32m--> 925\u001b[0m \u001b[43m_ensure_no_complex_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\visha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:588\u001b[0m, in \u001b[0;36m_ensure_no_complex_data\u001b[1;34m(array)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_no_complex_data\u001b[39m(array):\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    587\u001b[0m     ):\n\u001b[1;32m--> 588\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array))\n",
      "\u001b[1;31mValueError\u001b[0m: Complex data not supported\n[  7726.46607809-535.89642716j -36617.37582047+921.91373074j\n -52517.65484624-214.17991472j ... -11618.70913071-851.8317396j\n  45980.76264328+179.14825763j  56188.83518192+963.35016074j]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "from skimage.transform import downscale_local_mean, resize\n",
    "from sklearn.linear_model import Lasso\n",
    "import os\n",
    "\n",
    "\n",
    "# Path to the input video\n",
    "input_video_path = \"Testvideo (online-video-cutter.com).mp4\"\n",
    "\n",
    "# Check if the video file exists\n",
    "if not os.path.isfile(input_video_path):\n",
    "    print(\"Error: Input video file does not exist.\")\n",
    "    exit()\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "\n",
    "width = 0\n",
    "height = 0\n",
    "n_pixels = 0  # Assuming frames are of the same size as video frames\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break   \n",
    "    # Convert frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Downscale the original image to a smaller size for faster processing\n",
    "    downscaled_image = frame_gray\n",
    "    # Flatten the downsampled frame into a vector\n",
    "    frame_vector = downscaled_image.flatten()\n",
    "    sizeOfFrameVector = len(frame_vector)\n",
    "    count=1\n",
    "    for i in range(2,30):\n",
    "           if(sizeOfFrameVector%i==0):\n",
    "               count=i\n",
    "    n_pixels=int(sizeOfFrameVector/count )\n",
    "    height,width=downscaled_image.shape\n",
    "    break\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "print(\"Video properties:\")\n",
    "print(\"FPS:\", fps)\n",
    "print(\"Frame count:\", frame_count)\n",
    "print(\"Width:\", width)\n",
    "print(\"Height:\", height)\n",
    "\n",
    "# Load the sensing matrix\n",
    "n_measurements = 5000  # Number of measurements\n",
    "A = np.random.randn(n_measurements, n_pixels)\n",
    "\n",
    "print(n_pixels)\n",
    "\n",
    "\n",
    "\n",
    "output_video_path = \"Output.mp4\"\n",
    "out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "# Process each frame of the video\n",
    "# Process each frame of the video\n",
    "temp = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "\n",
    "    # Downscale the original image to a smaller size for faster processing\n",
    "    frame = blurred_image = cv2.GaussianBlur(frame_gray, (5, 5), 0)\n",
    "\n",
    "    # Reconstruct frame using compressive sensing\n",
    "    print(\"Reconstructing frame:\", temp)\n",
    "\n",
    "\n",
    "    # Flatten the downsampled frame into a vector\n",
    "    frame_vector = frame.flatten()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    #deviding vector in other part\n",
    "    factor= int(sizeOfFrameVector/count )\n",
    "    print(count,\" \", factor)         \n",
    "    buffer=0\n",
    "    # Initialize vector_of_frame as a list of lists\n",
    "    vector_of_frame = [[] for _ in range(count)]\n",
    "\n",
    "    # Assign values to vector_of_frame\n",
    "    buffer = 0\n",
    "    for i in range(0, count):\n",
    "        for j in range(0, factor):\n",
    "            vector_of_frame[i].append(frame_vector[buffer])\n",
    "            buffer += 1\n",
    "         \n",
    "\n",
    "\n",
    "    for i in range(0,count):\n",
    "            vec1=vector_of_frame[i]\n",
    "            # Take measurements\n",
    "            y = np.dot(A, vec1)\n",
    "\n",
    "            # Reconstruct the frame using L1 minimization (Lasso)\n",
    "            lasso = Lasso(alpha=0.01, max_iter=10000)  # Adjust alpha and max_iter\n",
    "            lasso.fit(A, y)\n",
    "            vector_of_frame[i] = lasso.coef_\n",
    "\n",
    "    # Reshape the reconstructed frame vector into the downsampled shape\n",
    "    # Initialize reconstructed_frame_vector as an empty list\n",
    "    reconstructed_frame_vector = []\n",
    "\n",
    "    # Append values to reconstructed_frame_vector\n",
    "    for i in range(0, count):\n",
    "        for j in range(0, factor):\n",
    "            reconstructed_frame_vector.append(vector_of_frame[i][j])\n",
    "\n",
    "    # Reshape the reconstructed frame vector into the downsampled shape\n",
    "    reconstructed_downscaled_frame = np.array(reconstructed_frame_vector).reshape(frame.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # Convert the upscaled reconstructed frame to uint8 mode\n",
    "    upscaled_reconstructed_frame_uint8 = (reconstructed_downscaled_frame * 255).astype(np.uint8)\n",
    "     \n",
    "     \n",
    "    reconstructed_frame = upscaled_reconstructed_frame_uint8\n",
    "\n",
    "\n",
    "    # Write reconstructed frame to output video\n",
    "    print(\"Writing frame to output video:\", temp)\n",
    "   \n",
    "    \n",
    "    # Save the upscaled reconstructed image\n",
    "    output_filename = f\"frame_{temp}.jpg\"\n",
    "    io.imsave(output_filename, reconstructed_frame) \n",
    "    # Write reconstructed frame to output video\n",
    "    out.write(cv2.cvtColor(reconstructed_frame, cv2.COLOR_GRAY2BGR))\n",
    "    temp += 1\n",
    "    \n",
    "\n",
    "# Release video capture and writer objects\n",
    "cv2.destroyAllWindows() \n",
    "out.release()\n",
    "cap.release()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
